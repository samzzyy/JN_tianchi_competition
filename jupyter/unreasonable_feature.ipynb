{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1381, 45) (150, 44)\n"
     ]
    }
   ],
   "source": [
    "df_train=pd.read_csv(\"E:\\\\jinnan\\\\train_after_clean.csv\")\n",
    "df_train=df_train[df_train['yield_rate']>0.87]\n",
    "df_train.drop(['B3', 'B13', 'A13', 'A18', 'A23'], axis=1, inplace=True)\n",
    "  \n",
    "df_test=pd.read_csv(\"E:\\\\jinnan\\\\test_after_clean.csv\")\n",
    "df_test.drop(['B3', 'B13', 'A13', 'A18', 'A23'], axis=1, inplace=True)\n",
    "\n",
    "print(df_train.shape,df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['A1', 'A10', 'A11', 'A12', 'A14', 'A15', 'A16', 'A17', 'A19', 'A2',\n",
      "       'A20', 'A20range', 'A21', 'A22', 'A24', 'A25', 'A26', 'A27', 'A28',\n",
      "       'A28range', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'B1', 'B10',\n",
      "       'B10range', 'B11', 'B11range', 'B12', 'B14', 'B2', 'B4', 'B4range',\n",
      "       'B5', 'B6', 'B7', 'B8', 'B9', 'B9range', 'numerical_id'],\n",
      "      dtype='object') (1531, 44)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "target=df_train['yield_rate']\n",
    "df_train.drop(columns=['yield_rate'],axis=1,inplace=True)\n",
    "data=pd.concat([df_train,df_test],axis=0)\n",
    "data[\"numerical_id\"]=data['id'].apply(lambda x: int(x[7:]))\n",
    "data.drop(columns=['id'],axis=1,inplace=True)\n",
    "print(data.columns,data.shape)\n",
    "raw_data_columns=data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "1\n",
      "(1531, 45) (1381, 44) (150, 44)\n",
      "(1531, 45) (1381, 1) (150, 1)\n"
     ]
    }
   ],
   "source": [
    "data['b14/a1_a3_a4_a19_b1_b12'] = data['B14']/(data['A1']+data['A3']+data['A4']+data['A19']+data['B1']+data['B12'])\n",
    "data_collist=list(data.columns)\n",
    "print(len(data_collist))\n",
    "for col in raw_data_columns:\n",
    "    data_collist.remove(col)\n",
    "print(len(data_collist))\n",
    "\n",
    "print(data.shape,df_train.shape,df_test.shape)\n",
    "df_train=data[data_collist][:df_train.shape[0]]\n",
    "df_test=data[data_collist][df_train.shape[0]:]\n",
    "print(data.shape,df_train.shape,df_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(\"E:\\\\jinnan\\\\unreason_feature_1_18_train.csv\",index=False)\n",
    "df_test.to_csv(\"E:\\\\jinnan\\\\unreason_feature_1_18_test.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold, RepeatedKFold\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train1: (1381, 78)\n",
      "train2: (1381, 105)\n",
      "train3: (1381, 780)\n",
      "train4: (1381, 272)\n",
      "train5: (1381, 1)\n",
      "Index(['A10', 'A11', 'A12', 'A14', 'A15', 'A16', 'A17', 'A19', 'A20',\n",
      "       'A20range',\n",
      "       ...\n",
      "       'B8minusB12', 'B8addB14', 'B8minusB14', 'B12addB12', 'B12minusB12',\n",
      "       'B12addB14', 'B12minusB14', 'B14addB14', 'B14minusB14',\n",
      "       'b14/a1_a3_a4_a19_b1_b12'],\n",
      "      dtype='object', length=1236) (1381, 1236) (1381, 1236)\n",
      "Index(['A10', 'A11', 'A12', 'A14', 'A15', 'A16', 'A17', 'A19', 'A20',\n",
      "       'A20range',\n",
      "       ...\n",
      "       'B8minusB12', 'B8addB14', 'B8minusB14', 'B12addB12', 'B12minusB12',\n",
      "       'B12addB14', 'B12minusB14', 'B14addB14', 'B14minusB14',\n",
      "       'b14/a1_a3_a4_a19_b1_b12'],\n",
      "      dtype='object', length=1236) (150, 1236) (150, 1236)\n"
     ]
    }
   ],
   "source": [
    "df_train=pd.read_csv(\"E:\\\\jinnan\\\\train_dispersion.csv\")\n",
    "df_train=df_train[df_train['yield_rate']>0.87]\n",
    "df_train.drop(['B3', 'B13', 'A13', 'A18', 'A23'], axis=1, inplace=True)\n",
    "for col in df_train.columns:\n",
    "    rate = df_train[col].value_counts(normalize=True, dropna=False).values[0]\n",
    "    if rate > 0.9:\n",
    "        df_train.drop(columns=[col], axis=1, inplace=True)\n",
    "label_array=df_train[\"yield_rate\"].values\n",
    "df_train[\"id\"]=df_train['id'].apply(lambda x: int(x[7:]))\n",
    "df_train.drop(columns=['yield_rate'],axis=1,inplace=True)\n",
    "print('train1:',df_train.shape)\n",
    "\n",
    "df_train2=pd.read_csv(\"E:\\\\jinnan\\\\train_binning_mean.csv\")\n",
    "print('train2:',df_train2.shape)\n",
    "df_train.index=range(df_train.shape[0])\n",
    "df_train2.index=range(df_train2.shape[0])\n",
    "df_train=pd.concat([df_train,df_train2],axis=1)\n",
    "\n",
    "df_train3=pd.read_csv(\"E:\\\\jinnan\\\\multiply_feature_train.csv\")\n",
    "print('train3:',df_train3.shape)\n",
    "df_train.index=range(df_train.shape[0])\n",
    "df_train3.index=range(df_train3.shape[0])\n",
    "df_train=pd.concat([df_train,df_train3],axis=1)\n",
    "\n",
    "df_train4=pd.read_csv(\"E:\\\\jinnan\\\\add_minus_feature_train.csv\")\n",
    "print('train4:',df_train4.shape)\n",
    "df_train.index=range(df_train.shape[0])\n",
    "df_train4.index=range(df_train4.shape[0])\n",
    "df_train=pd.concat([df_train,df_train4],axis=1)\n",
    "\n",
    "df_train5=pd.read_csv(\"E:\\\\jinnan\\\\unreason_feature_1_18_train.csv\")\n",
    "print('train5:',df_train5.shape)\n",
    "df_train.index=range(df_train.shape[0])\n",
    "df_train5.index=range(df_train5.shape[0])\n",
    "df_train=pd.concat([df_train,df_train5],axis=1)\n",
    "\n",
    "\n",
    "# train_array=df_train[selected_col].values\n",
    "train_array=df_train.values\n",
    "print(df_train.columns,df_train.shape,train_array.shape)\n",
    "\n",
    "df_test=pd.read_csv(\"E:\\\\jinnan\\\\test_dispersion.csv\")\n",
    "df_test.drop(['B3', 'B13', 'A13', 'A18', 'A23'], axis=1, inplace=True)\n",
    "for col in df_test.columns:\n",
    "    rate = df_test[col].value_counts(normalize=True, dropna=False).values[0]\n",
    "    if rate > 0.9:\n",
    "        df_test.drop(columns=[col], axis=1, inplace=True)\n",
    "columns_list=list(df_test.columns)\n",
    "# columns_list.remove(\"id\")\n",
    "sample_id=df_test[\"id\"]\n",
    "df_test[\"id\"]=df_test['id'].apply(lambda x: int(x[7:]))\n",
    "\n",
    "df_test2=pd.read_csv(\"E:\\\\jinnan\\\\testA_binning_mean.csv\")\n",
    "df_test=pd.concat([df_test,df_test2],axis=1)\n",
    "\n",
    "df_test3=pd.read_csv(\"E:\\\\jinnan\\\\multiply_feature_test.csv\")\n",
    "df_test=pd.concat([df_test,df_test3],axis=1)\n",
    "\n",
    "df_test4=pd.read_csv(\"E:\\\\jinnan\\\\add_minus_feature_test.csv\")\n",
    "df_test=pd.concat([df_test,df_test4],axis=1)\n",
    "\n",
    "df_test4=pd.read_csv(\"E:\\\\jinnan\\\\unreason_feature_1_18_test.csv\")\n",
    "df_test=pd.concat([df_test,df_test4],axis=1)\n",
    "# test_array=df_test[selected_col].values\n",
    "test_array=df_test.values\n",
    "print(df_test.columns,df_test.shape,test_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's l2: 0.000147975\tvalid_1's l2: 0.000175387\n",
      "[400]\ttraining's l2: 9.04199e-05\tvalid_1's l2: 0.000128338\n",
      "[600]\ttraining's l2: 7.0132e-05\tvalid_1's l2: 0.000117593\n",
      "[800]\ttraining's l2: 6.0563e-05\tvalid_1's l2: 0.000115029\n",
      "[1000]\ttraining's l2: 5.45281e-05\tvalid_1's l2: 0.000113646\n",
      "[1200]\ttraining's l2: 5.05137e-05\tvalid_1's l2: 0.000113071\n",
      "[1400]\ttraining's l2: 4.74975e-05\tvalid_1's l2: 0.000112657\n",
      "Early stopping, best iteration is:\n",
      "[1418]\ttraining's l2: 4.72533e-05\tvalid_1's l2: 0.000112602\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's l2: 0.00014627\tvalid_1's l2: 0.00018462\n",
      "[400]\ttraining's l2: 8.69312e-05\tvalid_1's l2: 0.000157036\n",
      "[600]\ttraining's l2: 6.6854e-05\tvalid_1's l2: 0.000150826\n",
      "[800]\ttraining's l2: 5.72009e-05\tvalid_1's l2: 0.000149144\n",
      "[1000]\ttraining's l2: 5.12286e-05\tvalid_1's l2: 0.000148952\n",
      "Early stopping, best iteration is:\n",
      "[965]\ttraining's l2: 5.21107e-05\tvalid_1's l2: 0.00014884\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's l2: 0.000144062\tvalid_1's l2: 0.000185291\n",
      "[400]\ttraining's l2: 8.75353e-05\tvalid_1's l2: 0.000149071\n",
      "[600]\ttraining's l2: 6.76604e-05\tvalid_1's l2: 0.000139362\n",
      "[800]\ttraining's l2: 5.83004e-05\tvalid_1's l2: 0.00013593\n",
      "[1000]\ttraining's l2: 5.251e-05\tvalid_1's l2: 0.00013463\n",
      "[1200]\ttraining's l2: 4.84748e-05\tvalid_1's l2: 0.000134407\n",
      "Early stopping, best iteration is:\n",
      "[1162]\ttraining's l2: 4.9125e-05\tvalid_1's l2: 0.000134293\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's l2: 0.000147483\tvalid_1's l2: 0.000177582\n",
      "[400]\ttraining's l2: 8.93869e-05\tvalid_1's l2: 0.000140835\n",
      "[600]\ttraining's l2: 6.90006e-05\tvalid_1's l2: 0.000132781\n",
      "[800]\ttraining's l2: 5.90576e-05\tvalid_1's l2: 0.000129896\n",
      "[1000]\ttraining's l2: 5.29458e-05\tvalid_1's l2: 0.000128828\n",
      "[1200]\ttraining's l2: 4.87632e-05\tvalid_1's l2: 0.000128484\n",
      "Early stopping, best iteration is:\n",
      "[1289]\ttraining's l2: 4.72438e-05\tvalid_1's l2: 0.000128323\n",
      "fold n°5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's l2: 0.000148729\tvalid_1's l2: 0.000166442\n",
      "[400]\ttraining's l2: 9.22617e-05\tvalid_1's l2: 0.000116092\n",
      "[600]\ttraining's l2: 7.10147e-05\tvalid_1's l2: 0.000104646\n",
      "[800]\ttraining's l2: 6.08439e-05\tvalid_1's l2: 0.00010307\n",
      "[1000]\ttraining's l2: 5.46297e-05\tvalid_1's l2: 0.000102868\n",
      "Early stopping, best iteration is:\n",
      "[953]\ttraining's l2: 5.58462e-05\tvalid_1's l2: 0.000102743\n",
      "CV score: 0.00012535\n"
     ]
    }
   ],
   "source": [
    "param = {'num_leaves': 120,\n",
    "         'min_data_in_leaf': 30, \n",
    "         'objective':'regression',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.01,\n",
    "         \"min_child_samples\": 30,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9 ,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'mse',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1}\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=2018)\n",
    "oof_lgb = np.zeros(train_array.shape[0])\n",
    "predictions_lgb = np.zeros(test_array.shape[0])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_array, label_array)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    trn_data = lgb.Dataset(train_array[trn_idx], label_array[trn_idx])\n",
    "    val_data = lgb.Dataset(train_array[val_idx], label_array[val_idx])\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=200, early_stopping_rounds = 100)\n",
    "    oof_lgb[val_idx] = clf.predict(train_array[val_idx], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    predictions_lgb += clf.predict(test_array, num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_lgb, label_array)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_lgb: 0.9257243411575136\n",
      "var_lgb: 0.0006523453109752762\n"
     ]
    }
   ],
   "source": [
    "df_predicted=pd.DataFrame({\"id\":sample_id.values,\"predicted\":predictions_lgb})\n",
    "df_predicted.loc[:,\"predicted\"]=df_predicted[\"predicted\"].apply(lambda x: round(x,3))\n",
    "df_predicted.to_csv(\"E:\\\\jinnan\\\\predict_result\\\\jinnan_add_minus_unreason_lgb_1_18.csv\",header=None,index=False)\n",
    "print(\"mean_lgb:\",np.mean(predictions_lgb))\n",
    "print(\"var_lgb:\",np.var(predictions_lgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
