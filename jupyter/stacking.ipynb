{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold, RepeatedKFold\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train1: (1381, 78)\n",
      "train2: (1381, 105)\n",
      "Index(['A10', 'A11', 'A12', 'A14', 'A15', 'A16', 'A17', 'A19', 'A20',\n",
      "       'A20range',\n",
      "       ...\n",
      "       'B14_to_B11_intTarget_0.0_mean', 'B14_to_B11_intTarget_1.0_mean',\n",
      "       'B14_to_B11_intTarget_2.0_mean', 'B14_to_B11_intTarget_3.0_mean',\n",
      "       'B14_to_B11_intTarget_4.0_mean', 'B14_to_B14_intTarget_0.0_mean',\n",
      "       'B14_to_B14_intTarget_1.0_mean', 'B14_to_B14_intTarget_2.0_mean',\n",
      "       'B14_to_B14_intTarget_3.0_mean', 'B14_to_B14_intTarget_4.0_mean'],\n",
      "      dtype='object', length=183) (1381, 183)\n",
      "Index(['A10', 'A11', 'A12', 'A14', 'A15', 'A16', 'A17', 'A19', 'A20',\n",
      "       'A20range',\n",
      "       ...\n",
      "       'B14_to_B11_intTarget_0.0_mean', 'B14_to_B11_intTarget_1.0_mean',\n",
      "       'B14_to_B11_intTarget_2.0_mean', 'B14_to_B11_intTarget_3.0_mean',\n",
      "       'B14_to_B11_intTarget_4.0_mean', 'B14_to_B14_intTarget_0.0_mean',\n",
      "       'B14_to_B14_intTarget_1.0_mean', 'B14_to_B14_intTarget_2.0_mean',\n",
      "       'B14_to_B14_intTarget_3.0_mean', 'B14_to_B14_intTarget_4.0_mean'],\n",
      "      dtype='object', length=183) (150, 183)\n"
     ]
    }
   ],
   "source": [
    "# df_train=pd.read_csv(\"E:\\\\jinnan\\\\train_after_clean.csv\")\n",
    "df_train=pd.read_csv(\"E:\\\\jinnan\\\\train_dispersion.csv\")\n",
    "df_train=df_train[df_train['yield_rate']>0.87]\n",
    "df_train.drop(['B3', 'B13', 'A13', 'A18', 'A23'], axis=1, inplace=True)\n",
    "for col in df_train.columns:\n",
    "    rate = df_train[col].value_counts(normalize=True, dropna=False).values[0]\n",
    "    if rate > 0.9:\n",
    "        df_train.drop(columns=[col], axis=1, inplace=True)\n",
    "label_array=df_train[\"yield_rate\"].values\n",
    "df_train[\"id\"]=df_train['id'].apply(lambda x: int(x[7:]))\n",
    "df_train.drop(columns=['yield_rate'],axis=1,inplace=True)\n",
    "print('train1:',df_train.shape)\n",
    "df_train2=pd.read_csv(\"E:\\\\jinnan\\\\train_binning_mean.csv\")\n",
    "print('train2:',df_train2.shape)\n",
    "df_train.index=range(df_train.shape[0])\n",
    "df_train2.index=range(df_train2.shape[0])\n",
    "df_train=pd.concat([df_train,df_train2],axis=1)\n",
    "train_array=df_train.values\n",
    "print(df_train.columns,df_train.shape)\n",
    "\n",
    "# df_test=pd.read_csv(\"E:\\\\jinnan\\\\test_after_clean.csv\")\n",
    "df_test=pd.read_csv(\"E:\\\\jinnan\\\\test_dispersion.csv\")\n",
    "df_test.drop(['B3', 'B13', 'A13', 'A18', 'A23'], axis=1, inplace=True)\n",
    "for col in df_test.columns:\n",
    "    rate = df_test[col].value_counts(normalize=True, dropna=False).values[0]\n",
    "    if rate > 0.9:\n",
    "        df_test.drop(columns=[col], axis=1, inplace=True)\n",
    "columns_list=list(df_test.columns)\n",
    "# columns_list.remove(\"id\")\n",
    "sample_id=df_test[\"id\"]\n",
    "df_test[\"id\"]=df_test['id'].apply(lambda x: int(x[7:]))\n",
    "\n",
    "df_test2=pd.read_csv(\"E:\\\\jinnan\\\\testA_binning_mean.csv\")\n",
    "df_test=pd.concat([df_test,df_test2],axis=1)\n",
    "test_array=df_test.values\n",
    "print(df_test.columns,df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's l2: 0.000195907\tvalid_1's l2: 0.000222516\n",
      "[400]\ttraining's l2: 0.000122574\tvalid_1's l2: 0.000151465\n",
      "[600]\ttraining's l2: 0.00010185\tvalid_1's l2: 0.000133858\n",
      "[800]\ttraining's l2: 9.26023e-05\tvalid_1's l2: 0.000126702\n",
      "[1000]\ttraining's l2: 8.6976e-05\tvalid_1's l2: 0.000123004\n",
      "[1200]\ttraining's l2: 8.32183e-05\tvalid_1's l2: 0.000120659\n",
      "[1400]\ttraining's l2: 8.03884e-05\tvalid_1's l2: 0.000119188\n",
      "[1600]\ttraining's l2: 7.80774e-05\tvalid_1's l2: 0.000117972\n",
      "[1800]\ttraining's l2: 7.62917e-05\tvalid_1's l2: 0.000117192\n",
      "[2000]\ttraining's l2: 7.47053e-05\tvalid_1's l2: 0.000116554\n",
      "[2200]\ttraining's l2: 7.33105e-05\tvalid_1's l2: 0.000116036\n",
      "Early stopping, best iteration is:\n",
      "[2279]\ttraining's l2: 7.28173e-05\tvalid_1's l2: 0.000115809\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's l2: 0.000188351\tvalid_1's l2: 0.000209668\n",
      "[400]\ttraining's l2: 0.000116997\tvalid_1's l2: 0.000157605\n",
      "[600]\ttraining's l2: 9.6541e-05\tvalid_1's l2: 0.000146646\n",
      "[800]\ttraining's l2: 8.63704e-05\tvalid_1's l2: 0.000143514\n",
      "[1000]\ttraining's l2: 8.02015e-05\tvalid_1's l2: 0.000141937\n",
      "[1200]\ttraining's l2: 7.60813e-05\tvalid_1's l2: 0.000140929\n",
      "[1400]\ttraining's l2: 7.31586e-05\tvalid_1's l2: 0.00014028\n",
      "[1600]\ttraining's l2: 7.08952e-05\tvalid_1's l2: 0.000139838\n",
      "[1800]\ttraining's l2: 6.88924e-05\tvalid_1's l2: 0.000139658\n",
      "[2000]\ttraining's l2: 6.73139e-05\tvalid_1's l2: 0.000139339\n",
      "[2200]\ttraining's l2: 6.60049e-05\tvalid_1's l2: 0.000139129\n",
      "[2400]\ttraining's l2: 6.47249e-05\tvalid_1's l2: 0.000138851\n",
      "Early stopping, best iteration is:\n",
      "[2404]\ttraining's l2: 6.47099e-05\tvalid_1's l2: 0.000138843\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's l2: 0.000189688\tvalid_1's l2: 0.00025731\n",
      "[400]\ttraining's l2: 0.000122869\tvalid_1's l2: 0.000182154\n",
      "[600]\ttraining's l2: 0.000100998\tvalid_1's l2: 0.000159451\n",
      "[800]\ttraining's l2: 9.05526e-05\tvalid_1's l2: 0.00015058\n",
      "[1000]\ttraining's l2: 8.40263e-05\tvalid_1's l2: 0.000145583\n",
      "[1200]\ttraining's l2: 7.96418e-05\tvalid_1's l2: 0.000142846\n",
      "[1400]\ttraining's l2: 7.63841e-05\tvalid_1's l2: 0.000141085\n",
      "[1600]\ttraining's l2: 7.38908e-05\tvalid_1's l2: 0.000139856\n",
      "[1800]\ttraining's l2: 7.1745e-05\tvalid_1's l2: 0.000139\n",
      "[2000]\ttraining's l2: 6.99969e-05\tvalid_1's l2: 0.00013842\n",
      "[2200]\ttraining's l2: 6.85463e-05\tvalid_1's l2: 0.000137962\n",
      "[2400]\ttraining's l2: 6.72603e-05\tvalid_1's l2: 0.000137666\n",
      "[2600]\ttraining's l2: 6.616e-05\tvalid_1's l2: 0.000137481\n",
      "Early stopping, best iteration is:\n",
      "[2584]\ttraining's l2: 6.61747e-05\tvalid_1's l2: 0.000137479\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's l2: 0.000193726\tvalid_1's l2: 0.000211122\n",
      "[400]\ttraining's l2: 0.000121471\tvalid_1's l2: 0.00015731\n",
      "[600]\ttraining's l2: 0.0001005\tvalid_1's l2: 0.000143582\n",
      "[800]\ttraining's l2: 9.06039e-05\tvalid_1's l2: 0.000137482\n",
      "[1000]\ttraining's l2: 8.42918e-05\tvalid_1's l2: 0.000134593\n",
      "[1200]\ttraining's l2: 7.99589e-05\tvalid_1's l2: 0.000132634\n",
      "[1400]\ttraining's l2: 7.67149e-05\tvalid_1's l2: 0.000131503\n",
      "[1600]\ttraining's l2: 7.42645e-05\tvalid_1's l2: 0.000130834\n",
      "[1800]\ttraining's l2: 7.22082e-05\tvalid_1's l2: 0.000130556\n",
      "[2000]\ttraining's l2: 7.04203e-05\tvalid_1's l2: 0.000130239\n",
      "[2200]\ttraining's l2: 6.89979e-05\tvalid_1's l2: 0.000130169\n",
      "[2400]\ttraining's l2: 6.76943e-05\tvalid_1's l2: 0.000129963\n",
      "Early stopping, best iteration is:\n",
      "[2478]\ttraining's l2: 6.72492e-05\tvalid_1's l2: 0.00012992\n",
      "fold n°5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's l2: 0.000195568\tvalid_1's l2: 0.00020075\n",
      "[400]\ttraining's l2: 0.000124428\tvalid_1's l2: 0.000130863\n",
      "[600]\ttraining's l2: 0.000103553\tvalid_1's l2: 0.000113953\n",
      "[800]\ttraining's l2: 9.31367e-05\tvalid_1's l2: 0.000108029\n",
      "[1000]\ttraining's l2: 8.68024e-05\tvalid_1's l2: 0.000105346\n",
      "[1200]\ttraining's l2: 8.25578e-05\tvalid_1's l2: 0.000104105\n",
      "[1400]\ttraining's l2: 7.93093e-05\tvalid_1's l2: 0.000103135\n",
      "[1600]\ttraining's l2: 7.68221e-05\tvalid_1's l2: 0.000102685\n",
      "[1800]\ttraining's l2: 7.48076e-05\tvalid_1's l2: 0.000102197\n",
      "[2000]\ttraining's l2: 7.31029e-05\tvalid_1's l2: 0.000101961\n",
      "[2200]\ttraining's l2: 7.17562e-05\tvalid_1's l2: 0.000101665\n",
      "[2400]\ttraining's l2: 7.05108e-05\tvalid_1's l2: 0.000101503\n",
      "Early stopping, best iteration is:\n",
      "[2495]\ttraining's l2: 6.99956e-05\tvalid_1's l2: 0.000101389\n",
      "CV score: 0.00012468\n"
     ]
    }
   ],
   "source": [
    "param = {'num_leaves': 120,\n",
    "         'min_data_in_leaf': 30, \n",
    "         'objective':'regression',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.01,\n",
    "         \"min_child_samples\": 30,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9 ,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'mse',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1}\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=2018)\n",
    "oof_lgb = np.zeros(train_array.shape[0])\n",
    "predictions_lgb = np.zeros(test_array.shape[0])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_array, label_array)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    trn_data = lgb.Dataset(train_array[trn_idx], label_array[trn_idx])\n",
    "    val_data = lgb.Dataset(train_array[val_idx], label_array[val_idx])\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=200, early_stopping_rounds = 100)\n",
    "    oof_lgb[val_idx] = clf.predict(train_array[val_idx], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    predictions_lgb += clf.predict(test_array, num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_lgb, label_array)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "[0]\ttrain-rmse:0.422932\tvalid_data-rmse:0.423819\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:0.257001\tvalid_data-rmse:0.25773\n",
      "[200]\ttrain-rmse:0.156615\tvalid_data-rmse:0.157312\n",
      "[300]\ttrain-rmse:0.095902\tvalid_data-rmse:0.096701\n",
      "[400]\ttrain-rmse:0.059306\tvalid_data-rmse:0.060168\n",
      "[500]\ttrain-rmse:0.037293\tvalid_data-rmse:0.038285\n",
      "[600]\ttrain-rmse:0.024087\tvalid_data-rmse:0.025363\n",
      "[700]\ttrain-rmse:0.016187\tvalid_data-rmse:0.018069\n",
      "[800]\ttrain-rmse:0.011512\tvalid_data-rmse:0.014177\n",
      "[900]\ttrain-rmse:0.008755\tvalid_data-rmse:0.012217\n",
      "[1000]\ttrain-rmse:0.007123\tvalid_data-rmse:0.011297\n",
      "[1100]\ttrain-rmse:0.006152\tvalid_data-rmse:0.010879\n",
      "[1200]\ttrain-rmse:0.005518\tvalid_data-rmse:0.010705\n",
      "[1300]\ttrain-rmse:0.005053\tvalid_data-rmse:0.010621\n",
      "[1400]\ttrain-rmse:0.004687\tvalid_data-rmse:0.010586\n",
      "[1500]\ttrain-rmse:0.004363\tvalid_data-rmse:0.010583\n",
      "[1600]\ttrain-rmse:0.004072\tvalid_data-rmse:0.01058\n",
      "[1700]\ttrain-rmse:0.003797\tvalid_data-rmse:0.010583\n",
      "[1800]\ttrain-rmse:0.003544\tvalid_data-rmse:0.010594\n",
      "Stopping. Best iteration:\n",
      "[1604]\ttrain-rmse:0.004059\tvalid_data-rmse:0.010576\n",
      "\n",
      "fold n°2\n",
      "[0]\ttrain-rmse:0.424042\tvalid_data-rmse:0.419362\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:0.257664\tvalid_data-rmse:0.254157\n",
      "[200]\ttrain-rmse:0.157037\tvalid_data-rmse:0.154297\n",
      "[300]\ttrain-rmse:0.096183\tvalid_data-rmse:0.093852\n",
      "[400]\ttrain-rmse:0.059484\tvalid_data-rmse:0.057663\n",
      "[500]\ttrain-rmse:0.037356\tvalid_data-rmse:0.036263\n",
      "[600]\ttrain-rmse:0.024077\tvalid_data-rmse:0.023922\n",
      "[700]\ttrain-rmse:0.01615\tvalid_data-rmse:0.017272\n",
      "[800]\ttrain-rmse:0.011423\tvalid_data-rmse:0.013892\n",
      "[900]\ttrain-rmse:0.008635\tvalid_data-rmse:0.012347\n",
      "[1000]\ttrain-rmse:0.006997\tvalid_data-rmse:0.011723\n",
      "[1100]\ttrain-rmse:0.005996\tvalid_data-rmse:0.011494\n",
      "[1200]\ttrain-rmse:0.005341\tvalid_data-rmse:0.01142\n",
      "[1300]\ttrain-rmse:0.004867\tvalid_data-rmse:0.011411\n",
      "[1400]\ttrain-rmse:0.004492\tvalid_data-rmse:0.011422\n",
      "[1500]\ttrain-rmse:0.004164\tvalid_data-rmse:0.011452\n",
      "Stopping. Best iteration:\n",
      "[1304]\ttrain-rmse:0.004852\tvalid_data-rmse:0.011408\n",
      "\n",
      "fold n°3\n",
      "[0]\ttrain-rmse:0.422401\tvalid_data-rmse:0.425951\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:0.25664\tvalid_data-rmse:0.259771\n",
      "[200]\ttrain-rmse:0.156381\tvalid_data-rmse:0.159237\n",
      "[300]\ttrain-rmse:0.095758\tvalid_data-rmse:0.098445\n",
      "[400]\ttrain-rmse:0.059217\tvalid_data-rmse:0.061499\n",
      "[500]\ttrain-rmse:0.037219\tvalid_data-rmse:0.039063\n",
      "[600]\ttrain-rmse:0.024018\tvalid_data-rmse:0.025786\n",
      "[700]\ttrain-rmse:0.016119\tvalid_data-rmse:0.018325\n",
      "[800]\ttrain-rmse:0.011429\tvalid_data-rmse:0.014424\n",
      "[900]\ttrain-rmse:0.008672\tvalid_data-rmse:0.012582\n",
      "[1000]\ttrain-rmse:0.007058\tvalid_data-rmse:0.011803\n",
      "[1100]\ttrain-rmse:0.006063\tvalid_data-rmse:0.01151\n",
      "[1200]\ttrain-rmse:0.005395\tvalid_data-rmse:0.011388\n",
      "[1300]\ttrain-rmse:0.004916\tvalid_data-rmse:0.01135\n",
      "[1400]\ttrain-rmse:0.004555\tvalid_data-rmse:0.011337\n",
      "[1500]\ttrain-rmse:0.004247\tvalid_data-rmse:0.011348\n",
      "Stopping. Best iteration:\n",
      "[1394]\ttrain-rmse:0.004578\tvalid_data-rmse:0.011335\n",
      "\n",
      "fold n°4\n",
      "[0]\ttrain-rmse:0.422949\tvalid_data-rmse:0.423757\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:0.256994\tvalid_data-rmse:0.256888\n",
      "[200]\ttrain-rmse:0.156616\tvalid_data-rmse:0.156019\n",
      "[300]\ttrain-rmse:0.095898\tvalid_data-rmse:0.095255\n",
      "[400]\ttrain-rmse:0.059289\tvalid_data-rmse:0.058748\n",
      "[500]\ttrain-rmse:0.037232\tvalid_data-rmse:0.036911\n",
      "[600]\ttrain-rmse:0.024024\tvalid_data-rmse:0.024166\n",
      "[700]\ttrain-rmse:0.016151\tvalid_data-rmse:0.017136\n",
      "[800]\ttrain-rmse:0.011437\tvalid_data-rmse:0.01358\n",
      "[900]\ttrain-rmse:0.00862\tvalid_data-rmse:0.011947\n",
      "[1000]\ttrain-rmse:0.006921\tvalid_data-rmse:0.011257\n",
      "[1100]\ttrain-rmse:0.005831\tvalid_data-rmse:0.010995\n",
      "[1200]\ttrain-rmse:0.005112\tvalid_data-rmse:0.010893\n",
      "[1300]\ttrain-rmse:0.004596\tvalid_data-rmse:0.01087\n",
      "[1400]\ttrain-rmse:0.004183\tvalid_data-rmse:0.010876\n",
      "Stopping. Best iteration:\n",
      "[1273]\ttrain-rmse:0.004719\tvalid_data-rmse:0.010868\n",
      "\n",
      "fold n°5\n",
      "[0]\ttrain-rmse:0.423228\tvalid_data-rmse:0.422635\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:0.257174\tvalid_data-rmse:0.256855\n",
      "[200]\ttrain-rmse:0.156732\tvalid_data-rmse:0.156491\n",
      "[300]\ttrain-rmse:0.09602\tvalid_data-rmse:0.095772\n",
      "[400]\ttrain-rmse:0.059419\tvalid_data-rmse:0.059362\n",
      "[500]\ttrain-rmse:0.037376\tvalid_data-rmse:0.03778\n",
      "[600]\ttrain-rmse:0.024148\tvalid_data-rmse:0.025199\n",
      "[700]\ttrain-rmse:0.016243\tvalid_data-rmse:0.01802\n",
      "[800]\ttrain-rmse:0.011588\tvalid_data-rmse:0.014272\n",
      "[900]\ttrain-rmse:0.008879\tvalid_data-rmse:0.01239\n",
      "[1000]\ttrain-rmse:0.007263\tvalid_data-rmse:0.011525\n",
      "[1100]\ttrain-rmse:0.006307\tvalid_data-rmse:0.01114\n",
      "[1200]\ttrain-rmse:0.005676\tvalid_data-rmse:0.010961\n",
      "[1300]\ttrain-rmse:0.005217\tvalid_data-rmse:0.010864\n",
      "[1400]\ttrain-rmse:0.004835\tvalid_data-rmse:0.010829\n",
      "[1500]\ttrain-rmse:0.004504\tvalid_data-rmse:0.010809\n",
      "[1600]\ttrain-rmse:0.004209\tvalid_data-rmse:0.0108\n",
      "[1700]\ttrain-rmse:0.003916\tvalid_data-rmse:0.010801\n",
      "[1800]\ttrain-rmse:0.003628\tvalid_data-rmse:0.010809\n",
      "Stopping. Best iteration:\n",
      "[1616]\ttrain-rmse:0.004166\tvalid_data-rmse:0.010796\n",
      "\n",
      "CV score: 0.00012102\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {'eta': 0.005, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8,\n",
    "          'objective': 'reg:linear', 'eval_metric': 'rmse', 'silent': True, 'nthread': 4}\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=2018)\n",
    "oof_xgb = np.zeros(len(df_train))\n",
    "predictions_xgb = np.zeros(len(df_test))\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_array, label_array)):\n",
    "    print(\"fold n°{}\".format(fold_ + 1))\n",
    "    trn_data = xgb.DMatrix(train_array[trn_idx], label_array[trn_idx])\n",
    "    val_data = xgb.DMatrix(train_array[val_idx], label_array[val_idx])\n",
    "\n",
    "    watchlist = [(trn_data, 'train'), (val_data, 'valid_data')]\n",
    "    clf = xgb.train(dtrain=trn_data, num_boost_round=20000, evals=watchlist, early_stopping_rounds=200,\n",
    "                    verbose_eval=100, params=xgb_params)\n",
    "    oof_xgb[val_idx] = clf.predict(xgb.DMatrix(train_array[val_idx]), ntree_limit=clf.best_ntree_limit)\n",
    "    predictions_xgb += clf.predict(xgb.DMatrix(test_array), ntree_limit=clf.best_ntree_limit) / folds.n_splits\n",
    "    \n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_xgb, label_array)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_lgb: 0.925775245467878\n",
      "var_lgb: 0.0006136959920948989\n",
      "mean_xgb: 0.9249380680918694\n",
      "var_xgb: 0.0006400234054478957\n"
     ]
    }
   ],
   "source": [
    "print(\"mean_lgb:\",np.mean(predictions_lgb))\n",
    "print(\"var_lgb:\",np.var(predictions_lgb))\n",
    "print(\"mean_xgb:\",np.mean(predictions_xgb))\n",
    "print(\"var_xgb:\",np.var(predictions_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample_1656</td>\n",
       "      <td>0.904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sample_1548</td>\n",
       "      <td>0.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sample_769</td>\n",
       "      <td>0.936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sample_1881</td>\n",
       "      <td>0.905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sample_1807</td>\n",
       "      <td>0.936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sample_145</td>\n",
       "      <td>0.923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sample_1212</td>\n",
       "      <td>0.929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sample_944</td>\n",
       "      <td>0.899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sample_829</td>\n",
       "      <td>0.934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sample_616</td>\n",
       "      <td>0.923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sample_1690</td>\n",
       "      <td>0.952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sample_114</td>\n",
       "      <td>0.948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sample_185</td>\n",
       "      <td>0.924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sample_1141</td>\n",
       "      <td>0.961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sample_1460</td>\n",
       "      <td>0.891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sample_1835</td>\n",
       "      <td>0.923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>sample_1539</td>\n",
       "      <td>0.899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sample_598</td>\n",
       "      <td>0.936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sample_1800</td>\n",
       "      <td>0.970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sample_394</td>\n",
       "      <td>0.897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sample_1146</td>\n",
       "      <td>0.913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>sample_149</td>\n",
       "      <td>0.971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>sample_1750</td>\n",
       "      <td>0.933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>sample_1977</td>\n",
       "      <td>0.943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>sample_1830</td>\n",
       "      <td>0.976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>sample_818</td>\n",
       "      <td>0.940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>sample_881</td>\n",
       "      <td>0.898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>sample_77</td>\n",
       "      <td>0.909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>sample_1240</td>\n",
       "      <td>0.971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>sample_309</td>\n",
       "      <td>0.892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>sample_49</td>\n",
       "      <td>0.898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>sample_474</td>\n",
       "      <td>0.899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>sample_1716</td>\n",
       "      <td>0.902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>sample_1169</td>\n",
       "      <td>0.965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>sample_1925</td>\n",
       "      <td>0.931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>sample_667</td>\n",
       "      <td>0.923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>sample_176</td>\n",
       "      <td>0.927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>sample_1908</td>\n",
       "      <td>0.904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>sample_160</td>\n",
       "      <td>0.932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>sample_35</td>\n",
       "      <td>0.955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>sample_1403</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>sample_1806</td>\n",
       "      <td>0.976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>sample_241</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>sample_1059</td>\n",
       "      <td>0.939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>sample_746</td>\n",
       "      <td>0.951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>sample_513</td>\n",
       "      <td>0.945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>sample_1088</td>\n",
       "      <td>0.937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>sample_1370</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>sample_523</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>sample_319</td>\n",
       "      <td>0.895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>sample_1923</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>sample_1296</td>\n",
       "      <td>0.937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>sample_1152</td>\n",
       "      <td>0.910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>sample_982</td>\n",
       "      <td>0.898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>sample_304</td>\n",
       "      <td>0.897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>sample_502</td>\n",
       "      <td>0.970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>sample_1951</td>\n",
       "      <td>0.927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>sample_386</td>\n",
       "      <td>0.969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>sample_362</td>\n",
       "      <td>0.941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>sample_522</td>\n",
       "      <td>0.933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  predicted\n",
       "0    sample_1656      0.904\n",
       "1    sample_1548      0.880\n",
       "2     sample_769      0.936\n",
       "3    sample_1881      0.905\n",
       "4    sample_1807      0.936\n",
       "5     sample_145      0.923\n",
       "6    sample_1212      0.929\n",
       "7     sample_944      0.899\n",
       "8     sample_829      0.934\n",
       "9     sample_616      0.923\n",
       "10   sample_1690      0.952\n",
       "11    sample_114      0.948\n",
       "12    sample_185      0.924\n",
       "13   sample_1141      0.961\n",
       "14   sample_1460      0.891\n",
       "15   sample_1835      0.923\n",
       "16   sample_1539      0.899\n",
       "17    sample_598      0.936\n",
       "18   sample_1800      0.970\n",
       "19    sample_394      0.897\n",
       "20   sample_1146      0.913\n",
       "21    sample_149      0.971\n",
       "22   sample_1750      0.933\n",
       "23   sample_1977      0.943\n",
       "24   sample_1830      0.976\n",
       "25    sample_818      0.940\n",
       "26    sample_881      0.898\n",
       "27     sample_77      0.909\n",
       "28   sample_1240      0.971\n",
       "29    sample_309      0.892\n",
       "..           ...        ...\n",
       "120    sample_49      0.898\n",
       "121   sample_474      0.899\n",
       "122  sample_1716      0.902\n",
       "123  sample_1169      0.965\n",
       "124  sample_1925      0.931\n",
       "125   sample_667      0.923\n",
       "126   sample_176      0.927\n",
       "127  sample_1908      0.904\n",
       "128   sample_160      0.932\n",
       "129    sample_35      0.955\n",
       "130  sample_1403      0.938\n",
       "131  sample_1806      0.976\n",
       "132   sample_241      0.935\n",
       "133  sample_1059      0.939\n",
       "134   sample_746      0.951\n",
       "135   sample_513      0.945\n",
       "136  sample_1088      0.937\n",
       "137  sample_1370      0.935\n",
       "138   sample_523      0.935\n",
       "139   sample_319      0.895\n",
       "140  sample_1923      0.973\n",
       "141  sample_1296      0.937\n",
       "142  sample_1152      0.910\n",
       "143   sample_982      0.898\n",
       "144   sample_304      0.897\n",
       "145   sample_502      0.970\n",
       "146  sample_1951      0.927\n",
       "147   sample_386      0.969\n",
       "148   sample_362      0.941\n",
       "149   sample_522      0.933\n",
       "\n",
       "[150 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predicted=pd.DataFrame({\"id\":sample_id.values,\"predicted\":predictions_lgb})\n",
    "df_predicted.loc[:,\"predicted\"]=df_predicted[\"predicted\"].apply(lambda x: round(x,3))\n",
    "df_predicted.to_csv(\"E:\\\\jinnan\\\\predict_result\\\\jinnan_idfea_binning_dispersion_lgb_1_11.csv\",header=None,index=False)\n",
    "df_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample_1656</td>\n",
       "      <td>0.906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sample_1548</td>\n",
       "      <td>0.879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sample_769</td>\n",
       "      <td>0.933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sample_1881</td>\n",
       "      <td>0.905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sample_1807</td>\n",
       "      <td>0.928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sample_145</td>\n",
       "      <td>0.926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sample_1212</td>\n",
       "      <td>0.932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sample_944</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sample_829</td>\n",
       "      <td>0.933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sample_616</td>\n",
       "      <td>0.928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sample_1690</td>\n",
       "      <td>0.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sample_114</td>\n",
       "      <td>0.947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sample_185</td>\n",
       "      <td>0.924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sample_1141</td>\n",
       "      <td>0.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sample_1460</td>\n",
       "      <td>0.893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sample_1835</td>\n",
       "      <td>0.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>sample_1539</td>\n",
       "      <td>0.893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sample_598</td>\n",
       "      <td>0.937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sample_1800</td>\n",
       "      <td>0.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sample_394</td>\n",
       "      <td>0.897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sample_1146</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>sample_149</td>\n",
       "      <td>0.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>sample_1750</td>\n",
       "      <td>0.934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>sample_1977</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>sample_1830</td>\n",
       "      <td>0.978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>sample_818</td>\n",
       "      <td>0.937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>sample_881</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>sample_77</td>\n",
       "      <td>0.903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>sample_1240</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>sample_309</td>\n",
       "      <td>0.885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>sample_49</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>sample_474</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>sample_1716</td>\n",
       "      <td>0.897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>sample_1169</td>\n",
       "      <td>0.963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>sample_1925</td>\n",
       "      <td>0.931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>sample_667</td>\n",
       "      <td>0.928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>sample_176</td>\n",
       "      <td>0.926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>sample_1908</td>\n",
       "      <td>0.902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>sample_160</td>\n",
       "      <td>0.933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>sample_35</td>\n",
       "      <td>0.958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>sample_1403</td>\n",
       "      <td>0.923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>sample_1806</td>\n",
       "      <td>0.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>sample_241</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>sample_1059</td>\n",
       "      <td>0.941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>sample_746</td>\n",
       "      <td>0.948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>sample_513</td>\n",
       "      <td>0.941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>sample_1088</td>\n",
       "      <td>0.934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>sample_1370</td>\n",
       "      <td>0.934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>sample_523</td>\n",
       "      <td>0.934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>sample_319</td>\n",
       "      <td>0.894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>sample_1923</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>sample_1296</td>\n",
       "      <td>0.940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>sample_1152</td>\n",
       "      <td>0.907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>sample_982</td>\n",
       "      <td>0.895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>sample_304</td>\n",
       "      <td>0.897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>sample_502</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>sample_1951</td>\n",
       "      <td>0.928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>sample_386</td>\n",
       "      <td>0.968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>sample_362</td>\n",
       "      <td>0.939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>sample_522</td>\n",
       "      <td>0.934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  predicted\n",
       "0    sample_1656      0.906\n",
       "1    sample_1548      0.879\n",
       "2     sample_769      0.933\n",
       "3    sample_1881      0.905\n",
       "4    sample_1807      0.928\n",
       "5     sample_145      0.926\n",
       "6    sample_1212      0.932\n",
       "7     sample_944      0.900\n",
       "8     sample_829      0.933\n",
       "9     sample_616      0.928\n",
       "10   sample_1690      0.950\n",
       "11    sample_114      0.947\n",
       "12    sample_185      0.924\n",
       "13   sample_1141      0.957\n",
       "14   sample_1460      0.893\n",
       "15   sample_1835      0.921\n",
       "16   sample_1539      0.893\n",
       "17    sample_598      0.937\n",
       "18   sample_1800      0.977\n",
       "19    sample_394      0.897\n",
       "20   sample_1146      0.908\n",
       "21    sample_149      0.977\n",
       "22   sample_1750      0.934\n",
       "23   sample_1977      0.935\n",
       "24   sample_1830      0.978\n",
       "25    sample_818      0.937\n",
       "26    sample_881      0.896\n",
       "27     sample_77      0.903\n",
       "28   sample_1240      0.973\n",
       "29    sample_309      0.885\n",
       "..           ...        ...\n",
       "120    sample_49      0.900\n",
       "121   sample_474      0.896\n",
       "122  sample_1716      0.897\n",
       "123  sample_1169      0.963\n",
       "124  sample_1925      0.931\n",
       "125   sample_667      0.928\n",
       "126   sample_176      0.926\n",
       "127  sample_1908      0.902\n",
       "128   sample_160      0.933\n",
       "129    sample_35      0.958\n",
       "130  sample_1403      0.923\n",
       "131  sample_1806      0.980\n",
       "132   sample_241      0.935\n",
       "133  sample_1059      0.941\n",
       "134   sample_746      0.948\n",
       "135   sample_513      0.941\n",
       "136  sample_1088      0.934\n",
       "137  sample_1370      0.934\n",
       "138   sample_523      0.934\n",
       "139   sample_319      0.894\n",
       "140  sample_1923      0.973\n",
       "141  sample_1296      0.940\n",
       "142  sample_1152      0.907\n",
       "143   sample_982      0.895\n",
       "144   sample_304      0.897\n",
       "145   sample_502      0.973\n",
       "146  sample_1951      0.928\n",
       "147   sample_386      0.968\n",
       "148   sample_362      0.939\n",
       "149   sample_522      0.934\n",
       "\n",
       "[150 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predicted=pd.DataFrame({\"id\":sample_id.values,\"predicted\":predictions_xgb})\n",
    "df_predicted.loc[:,\"predicted\"]=df_predicted[\"predicted\"].apply(lambda x: round(x,3))\n",
    "df_predicted.to_csv(\"E:\\\\jinnan\\\\predict_result\\\\jinnan_idfea_binning_dispersion_xgb_1_11.csv\",header=None,index=False)\n",
    "df_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import BayesianRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "fold 5\n",
      "fold 6\n",
      "fold 7\n",
      "fold 8\n",
      "fold 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.00011789490765092857"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stack = np.vstack([oof_lgb,oof_xgb]).transpose()\n",
    "test_stack = np.vstack([predictions_lgb, predictions_xgb]).transpose()\n",
    "\n",
    "folds_stack = RepeatedKFold(n_splits=5, n_repeats=2, random_state=4590)\n",
    "oof_stack = np.zeros(train_stack.shape[0])\n",
    "predictions = np.zeros(test_stack.shape[0])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds_stack.split(train_stack,label_array)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data, trn_y = train_stack[trn_idx], label_array[trn_idx]\n",
    "    val_data, val_y = train_stack[val_idx], label_array[val_idx]\n",
    "    \n",
    "    clf_3 = BayesianRidge()\n",
    "    clf_3.fit(trn_data, trn_y)\n",
    "    \n",
    "    oof_stack[val_idx] = clf_3.predict(val_data)\n",
    "    predictions += clf_3.predict(test_stack) / 10\n",
    "    \n",
    "mean_squared_error(label_array, oof_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.9255877522086162\n",
      "var: 0.000645417178952132\n"
     ]
    }
   ],
   "source": [
    "print(\"mean:\",np.mean(predictions))\n",
    "print(\"var:\",np.var(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample_1656</td>\n",
       "      <td>0.905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sample_1548</td>\n",
       "      <td>0.879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sample_769</td>\n",
       "      <td>0.934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sample_1881</td>\n",
       "      <td>0.905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sample_1807</td>\n",
       "      <td>0.932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sample_145</td>\n",
       "      <td>0.925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sample_1212</td>\n",
       "      <td>0.931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sample_944</td>\n",
       "      <td>0.899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sample_829</td>\n",
       "      <td>0.934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sample_616</td>\n",
       "      <td>0.926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sample_1690</td>\n",
       "      <td>0.951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sample_114</td>\n",
       "      <td>0.948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sample_185</td>\n",
       "      <td>0.924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sample_1141</td>\n",
       "      <td>0.960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sample_1460</td>\n",
       "      <td>0.892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sample_1835</td>\n",
       "      <td>0.922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>sample_1539</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sample_598</td>\n",
       "      <td>0.937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sample_1800</td>\n",
       "      <td>0.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sample_394</td>\n",
       "      <td>0.897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sample_1146</td>\n",
       "      <td>0.910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>sample_149</td>\n",
       "      <td>0.976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>sample_1750</td>\n",
       "      <td>0.934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>sample_1977</td>\n",
       "      <td>0.939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>sample_1830</td>\n",
       "      <td>0.978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>sample_818</td>\n",
       "      <td>0.939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>sample_881</td>\n",
       "      <td>0.897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>sample_77</td>\n",
       "      <td>0.905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>sample_1240</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>sample_309</td>\n",
       "      <td>0.887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>sample_49</td>\n",
       "      <td>0.899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>sample_474</td>\n",
       "      <td>0.897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>sample_1716</td>\n",
       "      <td>0.899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>sample_1169</td>\n",
       "      <td>0.965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>sample_1925</td>\n",
       "      <td>0.932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>sample_667</td>\n",
       "      <td>0.927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>sample_176</td>\n",
       "      <td>0.927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>sample_1908</td>\n",
       "      <td>0.903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>sample_160</td>\n",
       "      <td>0.933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>sample_35</td>\n",
       "      <td>0.958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>sample_1403</td>\n",
       "      <td>0.930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>sample_1806</td>\n",
       "      <td>0.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>sample_241</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>sample_1059</td>\n",
       "      <td>0.940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>sample_746</td>\n",
       "      <td>0.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>sample_513</td>\n",
       "      <td>0.943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>sample_1088</td>\n",
       "      <td>0.936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>sample_1370</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>sample_523</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>sample_319</td>\n",
       "      <td>0.894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>sample_1923</td>\n",
       "      <td>0.974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>sample_1296</td>\n",
       "      <td>0.939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>sample_1152</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>sample_982</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>sample_304</td>\n",
       "      <td>0.897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>sample_502</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>sample_1951</td>\n",
       "      <td>0.928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>sample_386</td>\n",
       "      <td>0.969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>sample_362</td>\n",
       "      <td>0.940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>sample_522</td>\n",
       "      <td>0.934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  predicted\n",
       "0    sample_1656      0.905\n",
       "1    sample_1548      0.879\n",
       "2     sample_769      0.934\n",
       "3    sample_1881      0.905\n",
       "4    sample_1807      0.932\n",
       "5     sample_145      0.925\n",
       "6    sample_1212      0.931\n",
       "7     sample_944      0.899\n",
       "8     sample_829      0.934\n",
       "9     sample_616      0.926\n",
       "10   sample_1690      0.951\n",
       "11    sample_114      0.948\n",
       "12    sample_185      0.924\n",
       "13   sample_1141      0.960\n",
       "14   sample_1460      0.892\n",
       "15   sample_1835      0.922\n",
       "16   sample_1539      0.896\n",
       "17    sample_598      0.937\n",
       "18   sample_1800      0.975\n",
       "19    sample_394      0.897\n",
       "20   sample_1146      0.910\n",
       "21    sample_149      0.976\n",
       "22   sample_1750      0.934\n",
       "23   sample_1977      0.939\n",
       "24   sample_1830      0.978\n",
       "25    sample_818      0.939\n",
       "26    sample_881      0.897\n",
       "27     sample_77      0.905\n",
       "28   sample_1240      0.973\n",
       "29    sample_309      0.887\n",
       "..           ...        ...\n",
       "120    sample_49      0.899\n",
       "121   sample_474      0.897\n",
       "122  sample_1716      0.899\n",
       "123  sample_1169      0.965\n",
       "124  sample_1925      0.932\n",
       "125   sample_667      0.927\n",
       "126   sample_176      0.927\n",
       "127  sample_1908      0.903\n",
       "128   sample_160      0.933\n",
       "129    sample_35      0.958\n",
       "130  sample_1403      0.930\n",
       "131  sample_1806      0.980\n",
       "132   sample_241      0.935\n",
       "133  sample_1059      0.940\n",
       "134   sample_746      0.950\n",
       "135   sample_513      0.943\n",
       "136  sample_1088      0.936\n",
       "137  sample_1370      0.935\n",
       "138   sample_523      0.935\n",
       "139   sample_319      0.894\n",
       "140  sample_1923      0.974\n",
       "141  sample_1296      0.939\n",
       "142  sample_1152      0.908\n",
       "143   sample_982      0.896\n",
       "144   sample_304      0.897\n",
       "145   sample_502      0.973\n",
       "146  sample_1951      0.928\n",
       "147   sample_386      0.969\n",
       "148   sample_362      0.940\n",
       "149   sample_522      0.934\n",
       "\n",
       "[150 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predicted=pd.DataFrame({\"id\":sample_id.values,\"predicted\":predictions})\n",
    "df_predicted.loc[:,\"predicted\"]=df_predicted[\"predicted\"].apply(lambda x: round(x,3))\n",
    "df_predicted.to_csv(\"E:\\\\jinnan\\\\predict_result\\\\jinnan_idfea_binning_dispersion_stacking_1_11.csv\",header=None,index=False)\n",
    "df_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
